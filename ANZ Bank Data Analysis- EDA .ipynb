{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>card_present_flag</th>\n",
       "      <th>bpay_biller_code</th>\n",
       "      <th>account</th>\n",
       "      <th>currency</th>\n",
       "      <th>long_lat</th>\n",
       "      <th>txn_description</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_code</th>\n",
       "      <th>first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>merchant_suburb</th>\n",
       "      <th>merchant_state</th>\n",
       "      <th>extraction</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>country</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>merchant_long_lat</th>\n",
       "      <th>movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>authorized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACC-1598451071</td>\n",
       "      <td>AUD</td>\n",
       "      <td>153.41 -27.95</td>\n",
       "      <td>POS</td>\n",
       "      <td>81c48296-73be-44a7-befa-d053f48ce7cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diana</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>Ashmore</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2018-08-01T01:01:15.000+0000</td>\n",
       "      <td>16.25</td>\n",
       "      <td>a623070bfead4541a6b0fff8a09e706c</td>\n",
       "      <td>Australia</td>\n",
       "      <td>CUS-2487424745</td>\n",
       "      <td>153.38 -27.99</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>authorized</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACC-1598451071</td>\n",
       "      <td>AUD</td>\n",
       "      <td>153.41 -27.95</td>\n",
       "      <td>SALES-POS</td>\n",
       "      <td>830a451c-316e-4a6a-bf25-e37caedca49e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diana</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2018-08-01T01:13:45.000+0000</td>\n",
       "      <td>14.19</td>\n",
       "      <td>13270a2a902145da9db4c951e04b51b9</td>\n",
       "      <td>Australia</td>\n",
       "      <td>CUS-2487424745</td>\n",
       "      <td>151.21 -33.87</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>authorized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACC-1222300524</td>\n",
       "      <td>AUD</td>\n",
       "      <td>151.23 -33.94</td>\n",
       "      <td>POS</td>\n",
       "      <td>835c231d-8cdf-4e96-859d-e9d571760cf0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2018-08-01T01:26:15.000+0000</td>\n",
       "      <td>6.42</td>\n",
       "      <td>feb79e7ecd7048a5a36ec889d1a94270</td>\n",
       "      <td>Australia</td>\n",
       "      <td>CUS-2142601169</td>\n",
       "      <td>151.21 -33.87</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>authorized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACC-1037050564</td>\n",
       "      <td>AUD</td>\n",
       "      <td>153.10 -27.66</td>\n",
       "      <td>SALES-POS</td>\n",
       "      <td>48514682-c78a-4a88-b0da-2d6302e64673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhonda</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>Buderim</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2018-08-01T01:38:45.000+0000</td>\n",
       "      <td>40.90</td>\n",
       "      <td>2698170da3704fd981b15e64a006079e</td>\n",
       "      <td>Australia</td>\n",
       "      <td>CUS-1614226872</td>\n",
       "      <td>153.05 -26.68</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>authorized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACC-1598451071</td>\n",
       "      <td>AUD</td>\n",
       "      <td>153.41 -27.95</td>\n",
       "      <td>SALES-POS</td>\n",
       "      <td>b4e02c10-0852-4273-b8fd-7b3395e32eb0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diana</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>Mermaid Beach</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2018-08-01T01:51:15.000+0000</td>\n",
       "      <td>3.25</td>\n",
       "      <td>329adf79878c4cf0aeb4188b4691c266</td>\n",
       "      <td>Australia</td>\n",
       "      <td>CUS-2487424745</td>\n",
       "      <td>153.44 -28.06</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status  card_present_flag bpay_biller_code         account currency  \\\n",
       "0  authorized                1.0              NaN  ACC-1598451071      AUD   \n",
       "1  authorized                0.0              NaN  ACC-1598451071      AUD   \n",
       "2  authorized                1.0              NaN  ACC-1222300524      AUD   \n",
       "3  authorized                1.0              NaN  ACC-1037050564      AUD   \n",
       "4  authorized                1.0              NaN  ACC-1598451071      AUD   \n",
       "\n",
       "        long_lat txn_description                           merchant_id  \\\n",
       "0  153.41 -27.95             POS  81c48296-73be-44a7-befa-d053f48ce7cd   \n",
       "1  153.41 -27.95       SALES-POS  830a451c-316e-4a6a-bf25-e37caedca49e   \n",
       "2  151.23 -33.94             POS  835c231d-8cdf-4e96-859d-e9d571760cf0   \n",
       "3  153.10 -27.66       SALES-POS  48514682-c78a-4a88-b0da-2d6302e64673   \n",
       "4  153.41 -27.95       SALES-POS  b4e02c10-0852-4273-b8fd-7b3395e32eb0   \n",
       "\n",
       "   merchant_code first_name  ...  age merchant_suburb merchant_state  \\\n",
       "0            NaN      Diana  ...   26         Ashmore            QLD   \n",
       "1            NaN      Diana  ...   26          Sydney            NSW   \n",
       "2            NaN    Michael  ...   38          Sydney            NSW   \n",
       "3            NaN     Rhonda  ...   40         Buderim            QLD   \n",
       "4            NaN      Diana  ...   26   Mermaid Beach            QLD   \n",
       "\n",
       "                     extraction amount                    transaction_id  \\\n",
       "0  2018-08-01T01:01:15.000+0000  16.25  a623070bfead4541a6b0fff8a09e706c   \n",
       "1  2018-08-01T01:13:45.000+0000  14.19  13270a2a902145da9db4c951e04b51b9   \n",
       "2  2018-08-01T01:26:15.000+0000   6.42  feb79e7ecd7048a5a36ec889d1a94270   \n",
       "3  2018-08-01T01:38:45.000+0000  40.90  2698170da3704fd981b15e64a006079e   \n",
       "4  2018-08-01T01:51:15.000+0000   3.25  329adf79878c4cf0aeb4188b4691c266   \n",
       "\n",
       "     country     customer_id merchant_long_lat movement  \n",
       "0  Australia  CUS-2487424745     153.38 -27.99    debit  \n",
       "1  Australia  CUS-2487424745     151.21 -33.87    debit  \n",
       "2  Australia  CUS-2142601169     151.21 -33.87    debit  \n",
       "3  Australia  CUS-1614226872     153.05 -26.68    debit  \n",
       "4  Australia  CUS-2487424745     153.44 -28.06    debit  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('ANZ synthesised transaction dataset.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference -This dataset contains 3 months' worth of transactions for 100 customers which includes purchases, recurring transactions and salary transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status', 'card_present_flag', 'bpay_biller_code', 'account',\n",
       "       'currency', 'long_lat', 'txn_description', 'merchant_id',\n",
       "       'merchant_code', 'first_name', 'balance', 'date', 'gender', 'age',\n",
       "       'merchant_suburb', 'merchant_state', 'extraction', 'amount',\n",
       "       'transaction_id', 'country', 'customer_id', 'merchant_long_lat',\n",
       "       'movement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns #We can observe that we have 22 columns to work with here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status                       object\n",
       "card_present_flag           float64\n",
       "bpay_biller_code             object\n",
       "account                      object\n",
       "currency                     object\n",
       "long_lat                     object\n",
       "txn_description              object\n",
       "merchant_id                  object\n",
       "merchant_code               float64\n",
       "first_name                   object\n",
       "balance                     float64\n",
       "date                 datetime64[ns]\n",
       "gender                       object\n",
       "age                           int64\n",
       "merchant_suburb              object\n",
       "merchant_state               object\n",
       "extraction                   object\n",
       "amount                      float64\n",
       "transaction_id               object\n",
       "country                      object\n",
       "customer_id                  object\n",
       "merchant_long_lat            object\n",
       "movement                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (12043, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import plot \n",
    "plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Unique customers, unique transactions and 3 months of data\n",
    "Before we explore explore each column individually, let's check for the following:\n",
    "\n",
    "100 unique customers (customer_id)\n",
    "Each row corresponds to a unique transaction ID (transaction_id)\n",
    "3 months worth of data (date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique customer ID's: \", data.customer_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference-We do indeed have 100 unique customers in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows in dataset: \", len(data))\n",
    "print(\"Number of unique transaction ID's: \", data.transaction_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - The number of unique transaction ID's correspond to the number of rows in the dataset which suggests that each row represent a single, unique transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start = \"2018-08-01\", end = \"2018-10-31\").difference(data.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - We do indeed have 3 months worth of data, starting from 1/8/2018 to 31/10/2018. However, there are only 91 unique days which means that there is one missing  and the missing date is '2018-08-16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Non-null count and data types and Missing value Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing_percentage = round(missing / len(data), 3) * 100\n",
    "pd.DataFrame({\"Number of missing values\": missing, \"Percentage\": missing_percentage}).sort_values(by = \"Percentage\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference -Both bpay_biller_code and merchant_code columns contain a significant number of missing values. We will deal with those missing values later.\n",
    "\n",
    "Let's examine the summary statistics of the numerical columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Descriptive statistics of numerical variablesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - The describe function is a good way to observe any anomalies in the numerical columns for example, we can check if the age and amount columns contain any negative values, or if a customer has an age of 150 etc. Here, I do not see any anomalies.\n",
    "\n",
    "It also provides an overview of some basic statistics for the amount column. However, we do not know the breakdown of these transaction amounts for example, what sort of transactions are they, who made them etc. We will explore this as we proceed with our further analysis.\n",
    "\n",
    "We can see see a huge spread between the maximum and minimum amount in the balance and amount columns. We will look into this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory data analysis (EDA) \n",
    "- Analysis of all the columns to check their information and draw certain insights from these columns . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import create_report \n",
    "report=create_report(data)\n",
    "report.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variable analysis \n",
    "Here, we will skip the following columns as they are merely identifiers and won't provide us with much information and we will analyse all the other categporical variables so we can draw some insights from the data:\n",
    "\n",
    "- bpay_biller_code\n",
    "- account\n",
    "- merchant_id\n",
    "- merchant_code\n",
    "- first_name\n",
    "- transaction_id\n",
    "- customer_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Status of transaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.status.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference -Status of of the individual transactions: authorised means transaction has already been approved, posted means still in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Card present flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.card_present_flag.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - We can see here that \n",
    "Card-not-present (CNP) transaction occurs when neither the cardholder nor the credit card is physically present at the time of the transaction. It's most common for orders that happen remotely over the phone, internet or mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Currency of transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.currency.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - All transactions are made in AUD. Can potentially drop this column because unnecessary since it does not provide us with any additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.long_lat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference -\n",
    "These are the coordinates where the transactions were made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Transaction description (types of transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txn_description.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.countplot(data.txn_description)\n",
    "plt.title(\"Number of transactions by category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - We can validate the purchases in detail as we proceed . These are the descriptions for each transaction. Transactions mostly consist of sales payment.\n",
    "\n",
    "Also, this might explain the missing values in the merchant columns as not all transactions are purchases of goods and services from merchants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyse the transaction vs Amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"txn_description\", \"amount\"]].groupby(\"txn_description\", as_index = False).mean().sort_values(by = \"amount\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.barplot(x = \"txn_description\", y = \"amount\", data = data)\n",
    "plt.title(\"Average transaction volume by category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - Pay/salary has the largest average transaction volume. Seems logical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.6 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gender.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "sns.countplot(data.gender)\n",
    "plt.title(\"Number of transactions by gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference-There are more male customer transactions than there are female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['gender','amount']].groupby(\"gender\", as_index=False).mean().sort_values(by='amount',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "sns.barplot(x = \"gender\", y = \"amount\", data = data)\n",
    "plt.title(\"Average transaction volume by gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference- Male has a higher average transaction volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.7 Merchant suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.merchant_state.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.8 Merchant State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['merchant_state'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 7))\n",
    "sns.countplot(data.merchant_state)\n",
    "plt.title(\"Number of transactions by state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - Similar to merchant suburb, these are the states where the transactions were made.\n",
    "\n",
    "NSW and VIC are the top 2 states in number of transactions. (New South Wales and Victoria )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"merchant_state\", \"amount\"]].groupby(\"merchant_state\", as_index = False).mean().sort_values(by = \"amount\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 7))\n",
    "sns.barplot(x = \"merchant_state\", y = \"amount\", data = data)\n",
    "plt.title(\"Average transaction volume by state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - ACT has the highest average transaction volume but the variance is quite large. This indicates which state not only made more transactions but the amounts they spend during their transactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.9 Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.extraction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - This appears to be the timestamp for each transaction. We can cross-reference this with the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"date\", \"extraction\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - Since we already have an existing date column, we can potentially extract only the time component out of the extraction column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.10 Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.country.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - \n",
    "All transactions were recorded within Australia. Therefore, can consider dropping this column since it does not provide us with any information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.11 Merchant longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.merchant_long_lat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference - These are the coordinates of the merchants' location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.12 Movement (debit/credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.movement.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5 ,5))\n",
    "sns.countplot(data.movement)\n",
    "plt.title(\"Number of transactions by movement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infernce - Most transactions are overwhelmingly debit transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "sns.barplot(x = \"movement\", y = \"amount\", data = data)\n",
    "plt.title(\"Average transaction volume by movement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - On the basis of amount most of the transactions were made by credit card . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Numerical variables \n",
    "- Now we will analyse the numerical variables as we move forward . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.distplot(data.balance)\n",
    "plt.title(\"Balance distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - We get a right skew distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "sns.boxplot(data.balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - We can see that Distribution of the balance feature has a long tail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Age of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.distplot(data.age)\n",
    "plt.title(\"Age distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - In this bank Majority of the customers belong in the 20-25 age bracket. Which also means they could hold zero balance accounts as students and could be working class too . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Transaction amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.distplot(data.amount)\n",
    "plt.title(\"Amount distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to focus on dropping unwanted columns, deal with missing values and finally create some additional features that will make our data analysis more detailed and robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import plot_missing\n",
    "plot_missing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: \", data.shape)\n",
    "data = data.drop([\"currency\", \"country\"], axis = 1)\n",
    "print(\"After: \", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - We drop the currency and column columns as they do not  provide us with new useful information . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Number of missing values\": missing, \"Percentage\": missing_percentage}).sort_values(by = \"Percentage\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate if there is a reason behind these missing values.\n",
    "\n",
    "Recall that not all transactions are purchases-related, could this imply the missing values in the merchant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonSales = data.loc[(data.txn_description != \"SALES-POS\") | (data.txn_description != \"POS\"), :]\n",
    "nonSales.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, missing values in the following columns all originate from non-purchases transactions: Let us proceed by filling these n/a values \n",
    "\n",
    "- card_present_flag\n",
    "- merchant_state\n",
    "- merchant_suburb\n",
    "- merchant_id\n",
    "- merchant_long_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"card_present_flag\", \"merchant_state\", \"merchant_suburb\", \"merchant_id\", \"merchant_long_lat\"]\n",
    "for col in cols:\n",
    "    data[col].fillna(\"n/a\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(ascending = False)\n",
    "missing_percentage = round(missing / len(data), 3) * 100\n",
    "pd.DataFrame({\"Number of missing values\": missing, \"Percentage\": missing_percentage}).sort_values(by = \"Percentage\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both merchant_code and bpay_biller_code are severely missing, around 93%. Therefore, we will drop those 2 columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"merchant_code\", \"bpay_biller_code\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create features for month, dayofweek and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_amount = pd.DataFrame(data.groupby(\"date\").amount.sum())\n",
    "daily_amount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a time series analysis after creating our dataset to analyse this data - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "ax.plot(daily_amount.index, daily_amount.amount)\n",
    "plt.title(\"Transaction volume from 1/8/2018 to 31/10/2018\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Transaction volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a cyclical pattern in transaction volume over the 3 month period. My hypothesis for this occurence is:\n",
    "\n",
    "Salaries are paid out only on certain days of the week\n",
    "People tend to spend more during the weekends (shopping, going out with friends etc)\n",
    "Therefore, to motivate this analysis, we will create 3 new features from both the date and extraction columns:\n",
    "\n",
    "- month\n",
    "- dayofweek\n",
    "- hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"month\"] = pd.DatetimeIndex(data.date).month\n",
    "data[\"dayofweek\"] = pd.DatetimeIndex(data.date).dayofweek\n",
    "data[[\"date\", \"month\", \"dayofweek\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference-In addition to month and day of week, we can also get the hour in which those transactions took place from the extraction column.\n",
    "\n",
    "First, I will update the extraction column such that it only contains the time. Then, I will create a new hour column which contains only the hour component of each transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.extraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"extraction\"] = [timestamp.split(\"T\")[1].split(\".\")[0] for timestamp in data.extraction]\n",
    "data.extraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hour\"] = [time.split(\":\")[0] for time in data.extraction]\n",
    "data[[\"extraction\", \"hour\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: \", data.hour.dtype)\n",
    "data[\"hour\"] = pd.to_numeric(data.hour)\n",
    "print(\"After: \", data.hour.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataframe is in a much better shape and we have new features to work with, let's now do a deep dive and see if we can gather any interesting insights about customers' transactional behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import plot_correlation \n",
    "plot_correlation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  dataprep.eda import plot_correlation \n",
    "plot_correlation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Purchases amount and overall amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt= data['amount']\n",
    "avg_trans_amt = amt.sum()/ amt.count()\n",
    "print(avg_trans_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This amount includes only Pos and Sales Pos as these are purchase amounts we are dealing with here . \n",
    "purchases_amount = data.loc[(data.txn_description == \"POS\") | (data.txn_description == \"SALES-POS\"), \"amount\"]\n",
    "purchases_amount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.distplot(purchases_amount)\n",
    "plt.title(\"Purchase transaction amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.distplot(data.amount)\n",
    "plt.title(\"Overall transaction amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference-Variance in overall transaction amount is much higher than purchases transaction amount due to the inclusion of salary payments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Transaction volume per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_monthly_volume = pd.DataFrame(data.groupby(\"customer_id\").amount.sum() / 3) \n",
    "customer_monthly_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "sns.distplot(customer_monthly_volume.amount)\n",
    "plt.title(\"Customers' monthly transaction volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Transaction volume over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "sns.barplot(x = \"month\", y = \"amount\", data = data)\n",
    "plt.title(\"Average transaction volume by month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - It looks like October month has most number of transactions made by volume . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_daily_volume = pd.DataFrame(data.groupby(\"dayofweek\").amount.mean())\n",
    "average_daily_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 5))\n",
    "ax.plot(average_daily_volume.index, average_daily_volume.amount)\n",
    "plt.title(\"Average transaction volume per day\")\n",
    "plt.ylabel(\"Transaction volume\")\n",
    "plt.xlabel(\"Day of week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Inference - We can see that Friday and Saturday have the lowest average transaction volume. Let's see a breakdown of these transactions by types of transactions.\n",
    "\n",
    "To simplify the categories, I will group all transactions into 3 categories:\n",
    "\n",
    "- Salary\n",
    "- Purchase\n",
    "- Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do a transaction Type Further analysis to proceed \n",
    "data.txn_description.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Frame filtering to find the categories that we can group together \n",
    "data.loc[data.txn_description == \"PAY/SALARY\", \"category\"] = \"Salary\"\n",
    "data.loc[(data.txn_description == \"SALES-POS\") | (data.txn_description == \"POS\"), \"category\"] = \"Purchase\"\n",
    "data.category.fillna(\"Others\", inplace = True)\n",
    "data[[\"txn_description\", \"category\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot = pd.DataFrame(data.groupby([\"dayofweek\", \"category\"]).amount.count())\n",
    "stacked_barplot.unstack().plot(kind = \"bar\", stacked = True, figsize = (12, 7))\n",
    "plt.title(\"Number of transactions each day by category\")\n",
    "plt.legend([\"Others\", \"Purchases\", \"Salaries\"])\n",
    "plt.ylabel(\"Number of transactions\")\n",
    "plt.xlabel(\"Day of week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - From above we can see that No salaries were paid on Friday and Saturday, therefore lower average transaction volume on those days.\n",
    "\n",
    "Also, it does not seem to appear that people spend more on purchases over the weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_hourly_volume = pd.DataFrame(data.groupby(\"hour\").amount.mean())\n",
    "average_hourly_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 5))\n",
    "ax.plot(average_hourly_volume.index, average_hourly_volume.amount)\n",
    "plt.title(\"Average transaction volume per hour\")\n",
    "plt.ylabel(\"Transaction volume\")\n",
    "plt.xlabel(\"Hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - When we analyse the transaction on the basis of hours we can see that Highest transaction volumes happen during the midday and late afternoon. Let's see a breakdown of these transactions by categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot = pd.DataFrame(data.groupby([\"hour\", \"category\"]).amount.count())\n",
    "stacked_barplot.unstack().plot(kind = \"bar\", stacked = True, figsize = (12, 7))\n",
    "plt.title(\"Number of transactions each hour by category\")\n",
    "plt.legend([\"Others\", \"Purchases\", \"Salaries\"])\n",
    "plt.ylabel(\"Number of transactions\")\n",
    "plt.xlabel(\"Hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Distance between customers and merchants-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore further the  - haversine library in Python which calculates the distance between two points on the Earth using their latitude and longitude. We can obtain the latitude and longitude of both the customers and merchants from the following columns:\n",
    "\n",
    "long_lat , \n",
    "merchant_long_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a final report for the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"long_lat\", \"merchant_long_lat\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import create_report \n",
    "report=create_report(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('C:/Users/Daniella/Forage ANZ/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
